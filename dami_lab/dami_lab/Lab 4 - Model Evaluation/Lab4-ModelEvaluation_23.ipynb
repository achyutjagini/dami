{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab contains various methods for evaluating the model created in the previous lab. So far, no automatic process has been performed to determine the optimal parameters. In this lab, you will learn how to perform a grid search to find good parameter settings and perform k-fold to ensure the model's generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "- 4-1. Model evaluation methods in scikit-learn\n",
    "  - K-fold\n",
    "  - Grid search\n",
    "  - Nested k-fold\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "- 4-2. Manual implementation\n",
    "  - K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1. Model evaluation methods in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first validation method we will learn is the **k-fold cross-validation**. This method is quite simple but is most widely used in practice. It divides the dataset in a (k-1):1 ratio and uses the right part ($\\frac{1}{k}$ of the dataset) as a **validation set** while training the model on the other $\\frac{k-1}{k}$ part. We change the validation set k times and run this validation k times with different parts of the dataset to generalize the validation performance. \n",
    "\n",
    "\n",
    "Split the data set in a (k-1):1 ratio, use the right part as the validation set, and train the model on the other part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the libraries\n",
    "\n",
    "Basic libraries used throughout this lab session. The random seed is set to ensure the same results as the instructor's ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "RANDOM_SEED = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset\n",
    "\n",
    "In this lab, we will use the same data as we used in the previous lab: **Connectionist Bench** from UCI Machine Learning Repository, which can be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data). This dataset has two classes: ***Mines***, ***Rocks***, with 60 attributes representing each data entity. More information can be found <a href=\"https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)\">here</a>. If you have downloaded the whole package of our labs, you will not have any problem of loading the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you must do is to load data and check it is correctly loaded. We will use pandas to load and manipulate it. Since there is no proper **head** for the table, you need to choose not to use the first row as a set of column names. You can refer to the previous lab to check whether the dataset is correctly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"sonar.all-data\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue to use scikit-learn, in which we manage labels and data attributes separately. Let's separate the data labels from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide the dataset into two parts: attributes (`X`) and labels (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(60, axis=1)\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task was to split the dataset into training and test sets in the previous lab. However, we will no longer have the test set. Instead, we will split our dataset into training and validation sets. Here, we use the validation set for further generalization of our model. However, we want to use the validation set for the model creation process to determine optimal parameters (e.g., together with grid search). We may need to split our dataset into three parts, including the test set, to get final performance measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are not trying optimization at this stage, we will divide our dataset into two parts using the **k-fold cross-validation** method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn provides two types of k-fold methods: k-fold and stratified k-fold. As the name suggests, stratified k-fold preserves the proportions of labels when separating datasets. We will try both and see which produces a better model for our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's try a normal **k-fold** method. The first step is the same as other scikit-learn functions: import the class from the library package and create an instance. You can find k-fold in the *model_selection* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize our instance as we did before for classifiers. Here, we need to specify the number of splits (`n_splits`). Let's set it to five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize an KFold instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put our dataset into the **split** method of our instance. It will automatically divide our dataset with a 4:1 ratio five times following the original order of the dataset. This method only returns the indices, so we need to use those indices to get the actual data points. If we want to shuffle the datasets, we must predefine the option when creating the instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the split method to iterate different indices for each fold and print the dataset using the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    # CHECK THE ORDERS OF THE SPLIT TRAINING SET AND THE TEST SET\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try the **stratified k-fold** method. You can also find it in the model_selection package. We will use the same number of splits (five)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize a StratifiedKFold instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we also need to give the split method our original **y** value so that the algorithm knows the label distribution and keeps it in the divided dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the split method to iterate different indices for each fold and print the dataset using the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use this index to get a partitioned validation set and a partitioned training set, but that is too much work because there are many manual implementations. Scikit-learn provides another option to automate the cross-validation process called **cross_val_score**. This method lists all performance scores from k iterations (i.e., cross-validation scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this method, we need to go through the same model creation process we learned last time. Let's make a basic SVC classifier with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initialize a SVC instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function uses **StratifiedKFold** inside, so you do not need to worry about the class distribution. If you want to use **KFold** instead of **StratifiedKFold**, you may create a **KFold** instance and put it as a parameter into the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return a list of cross validation scores by using `cross_val_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMAL CASE: StratifiedKFold is applied\n",
    "scores = cross_val_score(clf, X, y, cv=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return a list of cross validation scores by using cross_val_score with a customized KFold saved as `kf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIAL CASE: Normal KFold is applied\n",
    "kf = KFold(n_splits=5)\n",
    "scores2 = cross_val_score(clf, X, y, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores), np.mean(scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default score is **accuracy**, but you can also display other scores, such as precision, recall, and the F1 score. Let's display the F1 score instead of accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return a list of cross validation scores by using cross_val_score with a customized scoring option (f1_macro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores3 = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last exercise, we tried to increase the test accuracy by adding different parameter values. However, this is practically impossible because you cannot always wait for the model to finish training, and you cannot manually put in numerous parameter combinations. In this situation, **grid search** can be used to find the optimal parameter given a specific range of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It receives sets of parameters as a dictionary list (a list having dictionaries as its entities). Inside each dictionary, we specify the possible combination of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a parameter grid running two grid search rounds, where one contains C and kernel and the other contains C, gamma, and kernel as options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as always, we need to create an instance with all our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define a grid search instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(clf, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can directly fit this instance with our dataset. Since it will run cross-validation inside, we do not need to put any other split dataset, but the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the search to our dataset (`X`, `y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our first grid search is done! You can find out the best score and the best estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return the best estimator by using the attribute best_estimator_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return the best score by using the attribute best_score_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested k-fold is used to estimate optimal parameters, but we do not have enough data entities in our dataset to separate it into three parts (training, validation, and test). This method first runs k-fold to run grid-search and runs another k-fold to test the performance measure. Therefore, it must shuffle the dataset before running each k-fold since its strategy is to estimate parameters and test using a different portion of the same dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to use a default SVC classifier again!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate a SVC instance with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of nested k-fold is to use one cross-validation to **create** and the other cross-validation to **evaluate** the models and pick the best one. The second cross-validation works like a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We eventually need a loop, but let's learn about a basic structure first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to set two different k-fold cross-validation instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate two KFold instances, with the same option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cv = KFold(n_splits=4, shuffle=True, random_state=RANDOM_SEED) # inner k-fold\n",
    "eval_cv = KFold(n_splits=4, shuffle=True, random_state=RANDOM_SEED+1) # outer k-fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also need to set one grid-search instance with the first k-fold instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate one grid search instance with `model_cv` as an option for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=model_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this best score is not useful since it evaluates the same portion of the training dataset. Therefore, now we need to use our second cross-validation instance to get a more reasonable cross-validation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate one grid search instance with `eval_cv` as an option for cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(search, X=X, y=y, cv=eval_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2. Manual implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to implement k-fold. It is a straightforward algorithm having only three steps: 1) divide the data into k folds, 2) choose one of the chunks as one set and all the other chunks as another set, 3) repeat 1-2 k times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also try to make the same structure with the one in the scikit-learn library so that we can quickly test and compare!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold_Manual():\n",
    "    def __init__(self, n_splits=5, shuffle=False, random_state=RANDOM_SEED):\n",
    "        return\n",
    "        \n",
    "    def split(self, X):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KFold_Manual():\n",
    "    def __init__(self, n_splits=5, shuffle=False, random_state=RANDOM_SEED):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = RANDOM_SEED\n",
    "\n",
    "    def split(self, X):\n",
    "        #extract the indices\n",
    "        indices = X.index.values\n",
    "        #shuffle\n",
    "        if self.shuffle == True:\n",
    "            indices = np.random.shuffle(indices, random_state = self.random_state)\n",
    "        \n",
    "        #split\n",
    "        split_indices = np.array_split(indices, self.n_splits)\n",
    "        \n",
    "        #index manipulation\n",
    "        results = []\n",
    "\n",
    "        for i in range(self.n_splits):\n",
    "            splits = [np.zeros(0), np.zeros(0)]\n",
    "\n",
    "            for idx, val in enumerate(split_indices):\n",
    "                if idx != i:\n",
    "                    splits[0] = np.concatenate((splits[0], val))\n",
    "                else:\n",
    "                    splits[1] = np.concatenate((splits[1], val))\n",
    "                \n",
    "            results.append(splits)\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's copy and paste the code above and run it here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold_Manual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF LAB 4"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
